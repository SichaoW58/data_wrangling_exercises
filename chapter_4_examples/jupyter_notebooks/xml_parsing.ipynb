{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "xml_parsing.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyTkYmWQyyiG"
      },
      "source": [
        "# An example of reading data from a .xml file with Python, using the \"lxml\" library.\n",
        "# First, you'll need pip install the lxml library: https://pypi.org/project/lxml/\n",
        "# A helpful tutorial can be found here: https://lxml.de/tutorial.html\n",
        "# The data used here is an instance of\n",
        "# https://api.stlouisfed.org/fred/series/observations?series_id=U6RATE&api_key=YOUR_API_KEY_HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQNsG5awyyiU"
      },
      "source": [
        "# specify the particular \"chapter\" you want to import from the \"lxml\" library\n",
        "# in this case, \"etree\", which stands for \"ElementTree\"\n",
        "from lxml import etree\n",
        "\n",
        "# we'll also import the \"csv\" library because we want to convert our workbook\n",
        "# to a `.csv`\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfnMM-URy0KV"
      },
      "source": [
        "# # UNCOMMENT BELOW TO USE WITH GOOGLE COLAB\n",
        "# # Import PyDrive and associated libraries.\n",
        "# # This only needs to be done once per notebook.\n",
        "# # Documentation found here: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# # This only needs to be done once per notebook.\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MACppzHLy0ND"
      },
      "source": [
        "# # UNCOMMENT BELOW TO USE WITH GOOGLE COLAB\n",
        "# # Link to data file stored in Drive: https://drive.google.com/file/d/1gPGaDTT9Nn6BtlTtVp7gQLSuocMyIaLU/view?usp=sharing\n",
        "# file_id = '1gPGaDTT9Nn6BtlTtVp7gQLSuocMyIaLU' # notice where this string comes from in link above\n",
        "\n",
        "# imported_file = drive.CreateFile({'id': file_id}) # creating an accessible copy of the shared data file\n",
        "# print(imported_file['title'])  # it should print the title of desired file\n",
        "# imported_file.GetContentFile(imported_file['title']) # refer to it in this notebook by the same name as it has in Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brMqftZHyyiW"
      },
      "source": [
        "# in this instance, there's nothing within the data file that really identifies\n",
        "# what the data is, so we'll make the filename a separate variable so that\n",
        "# we can use it to both load our source data and label our output file\n",
        "filename = \"U6_FRED_data\"\n",
        "\n",
        "# open is a built-in function that takes two \"ingredients\":\n",
        "# 1. a file name (the file should be in the same folder as this Python script or notebook)\n",
        "# 2. a \"mode\": \"r\" for \"read\" or \"w\" for \"write\"\n",
        "# Because the lxml library expects byte data rather than text, in this case the\n",
        "# second argument \"ingredient\" is \"rb\" for \"read bytes\"\n",
        "xml_source_file = open(filename+\".xml\",\"rb\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrnCcfk9yyiY"
      },
      "source": [
        "# pass our xml_source_file as an ingredient to the the lxml etree library's parse method\n",
        "# and store the result in a variable called `xml_doc`\n",
        "xml_doc = etree.parse(xml_source_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj_s5xgPyyiZ"
      },
      "source": [
        "# there is a lot of malformed xml out there! in order to make sure that\n",
        "# what looks like good xml actually *is*, we'll start by getting\n",
        "# the current xml document's \"root\" element\n",
        "document_root = xml_doc.getroot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-AJTnnEyyia"
      },
      "source": [
        "# let's print it out to see what it looks like. Because it's currently\n",
        "# stored as byte data, we need to use the etree.tostring() method in order\n",
        "# to see anything useful\n",
        "print(etree.tostring(document_root))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WvHA0Sgyyid"
      },
      "source": [
        "# if the document_root is a well-formed XML element, continue with our\n",
        "# wrangling efforts\n",
        "if etree.iselement(document_root):\n",
        "\n",
        "\n",
        "    # create our output file, naming it \"xml_\"+filename\n",
        "    output_file = open(\"xml_\"+filename+\".csv\",\"w\")\n",
        "\n",
        "    # there is a \"writer\" recipe that lets us easily write `.csv`-formatted rows\n",
        "    # so, just as we did when \"reading\", now that we've opened our `output_file`\n",
        "    # we'll use this recipe to easily write rows, instead of reading them\n",
        "    output_writer = csv.writer(output_file)\n",
        "\n",
        "    # thanks to lxml, each xml element (or \"node\") has a property called \"attrib\"\n",
        "    # whose data type is a Python dictionary (dict).\n",
        "    # a `dict` type has several methods of accessing its contents\n",
        "    # including the `.keys()`, `.values()`, and `.items()` methods, which return\n",
        "    # lists (see: https://docs.python.org/3/library/stdtypes.html#typesmapping)\n",
        "    # in this case, the list returned by the `.keys()` method will be useful as column headers\n",
        "    # so we'll write those to our output file first\n",
        "    # in this case, all of our elements are identical, so we can just grab the\n",
        "    # first one (document_root[0]) and use its keys as the column headers\n",
        "    output_writer.writerow(document_root[0].attrib.keys())\n",
        "\n",
        "    # now, we need to loop through every element in our XML file\n",
        "    # in the lxml library, XML elements are already lists, so we can use a\n",
        "    # simple `for...in` loop to go through it: https://lxml.de/tutorial.html#elements-are-lists\n",
        "    for child in document_root:\n",
        "\n",
        "        # now we'll use the `.values()` method to get each element's values\n",
        "        # as a list, and then use that along with the\n",
        "        # `writerow` recipe directly\n",
        "        output_writer.writerow(child.attrib.values())\n",
        "\n",
        "    # just for good measure, let's close the `.csv` file we just wrote all that\n",
        "    # data to...\n",
        "    output_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV7ZmeIqzBoA"
      },
      "source": [
        "# # UNCOMMENT BELOW TO USE WITH GOOGLE COLAB\n",
        "# from google.colab import files\n",
        "\n",
        "# files.download(\"xml_\"+filename+\".csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}