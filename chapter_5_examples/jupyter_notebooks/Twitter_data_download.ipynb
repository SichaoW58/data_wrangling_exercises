{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNCOMMENT BELOW TO USE WITH GOOGLE COLAB\n",
    "# # Import PyDrive and associated libraries.\n",
    "# # This only needs to be done once per notebook.\n",
    "# # Documentation found here: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# # Authenticate and create the PyDrive client.\n",
    "# # This only needs to be done once per notebook.\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNCOMMENT BELOW TO USE WITH GOOGLE COLAB\n",
    "# # Link to data file stored in Drive: LINK TO YOUR CREDENTIALS FILE ON DRIVE\n",
    "# file_id = 'FILE_ID_OF_YOUR_CREDENTIALS_FILE_ON_DRIVE' # notice where this string comes from in link above\n",
    "\n",
    "# imported_file = drive.CreateFile({'id': file_id}) # creating an accessible copy of the shared data file\n",
    "# print(imported_file['title'])  # it should print the title of desired file\n",
    "# imported_file.GetContentFile(imported_file['title']) # refer to it in this notebook by the same name as it has in Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Twitter_credentials import auth_ready_key\n",
    "\n",
    "# include the requests library in order to get data from the web\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the Twitter endpoint that we can use to request an access token\n",
    "# or bearer token\n",
    "auth_url = 'https://api.twitter.com/oauth2/token'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a dict containing the information the authorization endpoint wants\n",
    "# in order to return an access token to us. This includes the \"header\"\n",
    "# information, which gives the endpoint our encoded key and tells it about\n",
    "# the data formatting\n",
    "auth_headers = {\n",
    "    'Authorization': 'Basic '+auth_ready_key,\n",
    "    'Content-Type': 'application/x-www-form-urlencoded;charset=UTF-8'\n",
    "}\n",
    "\n",
    "# we also need to pass along information about what we're asking for. The\n",
    "# format of both the headers and the data is decided by the API provider,\n",
    "# so we're just following their directions here\n",
    "auth_data = {\n",
    "    'grant_type': 'client_credentials'\n",
    "}\n",
    "\n",
    "# now we actually make our complete request to the authorization endpoint.\n",
    "# The data sent back will be stored in this variable\n",
    "auth_resp = requests.post(auth_url, headers=auth_headers, data=auth_data)\n",
    "\n",
    "# pull the access token out of the data sent back from the authorization\n",
    "# endpoint\n",
    "access_token = auth_resp.json()['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have an access/bearer token, we're ready to request some data!\n",
    "# we'll create a new dict that includes this token\n",
    "search_headers = {\n",
    "    'Authorization': 'Bearer ' + access_token\n",
    "}\n",
    "\n",
    "# this is the Twitter search API endpoint for version 1.1 of the API\n",
    "search_url  = 'https://api.twitter.com/1.1/search/tweets.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll create a new dict that includes our search query parameters\n",
    "# in this case, our query (`q`) is \"Python\", we're looking for recent results\n",
    "# and we want a maximum of 4 Tweets back.\n",
    "search_params = {\n",
    "    'q': 'Python',\n",
    "    'result_type': 'recent',\n",
    "    'count': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can build and send our data request; the data sent back will be stored\n",
    "# in this variable\n",
    "search_resp = requests.get(search_url, headers=search_headers, params=search_params)\n",
    "\n",
    "# we'll store the data we get back in a variable, because we're both going\n",
    "# to write it to a file and print out some of its contents\n",
    "Twitter_data = search_resp.json()\n",
    "\n",
    "# we'll open an output file where we can store the results\n",
    "Twitter_output_file = open(\"Twitter_search_results.json\", \"w\")\n",
    "\n",
    "# write the returned Twitter data to our output file\n",
    "# because the response is a JSON object, we have to use the built-in `str()`\n",
    "# recipe to convert it to a string before we can write it to our file\n",
    "Twitter_output_file.write(str(Twitter_data))\n",
    "\n",
    "# close the output file\n",
    "Twitter_output_file.close()\n",
    "\n",
    "# because there is a LOT of information in each result, we're going to print\n",
    "# out the text of each Tweet returned, just to get a sense of what's in the\n",
    "# data. The `statuses` is the list of Tweets in the JSON object, and the\n",
    "# actual text of the Tweets is can be accessed with the key/property `text`\n",
    "for a_Tweet in Twitter_data['statuses']:\n",
    "    print(a_Tweet['text'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UNCOMMENT BELOW TO USE WITH GOOGLE COLAB\n",
    "# from google.colab import files\n",
    "\n",
    "# files.download(\"Twitter_search_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
